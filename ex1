import numpy as np
from sklearn.datasets import load_diabetes
diabetes = load_diabetes()

df_x=np.array(diabetes.data)
df_y=np.array(diabetes.target)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)

W = np.random.rand(10)
b = np.random.rand()

def model(X, W, b):
    predictions = 0
    for i in range(10):
        predictions += X[:, i] * W[i]
    predictions += b
    return predictions

def MSE(a, b):
    mse = ((a - b) ** 2).mean()
    return mse
def loss(X, W, b, y):
    predictions = model(X, W, b)
    L = MSE(predictions, y)
    return L

def gradient(X, W, b, y):
  N = len(y)
  y_pred = model(X, W, b)
  dW = 1/N * 2 * X.T.dot(y_pred - y)
  db = 2 * (y_pred - y).mean()
  return dW, db

LEARNING_RATE = 0.01
losses = []

for i in range(1, 500000):
dW, db = gradient(X_train, W, b, y_train)
W -= LEARNING_RATE * dW
b -= LEARNING_RATE * db
L = loss(X_train, W, b, y_train)
losses.append(L)
    
import matplotlib.pyplot as plt
plt.plot(losses)
plt.show()

prediction = model(X_test, W, b)
mse = loss(X_test, W, b, y_test)
plt.scatter(X_test[:, 0], y_test, label="true")
plt.scatter(X_test[:, 0], prediction, label="pred")
plt.legend()
plt.show()
print("mse:{}".format(mse))
